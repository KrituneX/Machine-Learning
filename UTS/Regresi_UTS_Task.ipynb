{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUVrdO9cjalCnwMhjncq8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrituneX/Machine-Learning/blob/main/UTS/Regresi_UTS_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qlX3ktceywAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e073efa-2d26-47e0-cb41-f16dc859bfde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qwUQGbXIW_XJpczmSzfvVJUe2LAQaDx5\n",
            "From (redirected): https://drive.google.com/uc?id=1qwUQGbXIW_XJpczmSzfvVJUe2LAQaDx5&confirm=t&uuid=f0abc60c-5ab2-4d7a-b260-078a5af249ff\n",
            "To: /content/RegresiUTSTelkom.csv\n",
            "100% 443M/443M [00:10<00:00, 41.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1qwUQGbXIW_XJpczmSzfvVJUe2LAQaDx5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "0aChuOHXw_3D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "source": [
        "# 1. Pengumpulan & Pembersihan Data\n",
        "df = pd.read_csv(\"RegresiUTSTelkom.csv\")\n",
        "\n",
        "# 1a. Median-split target jadi biner\n",
        "target = df.columns[-1]\n",
        "df['label'] = (df[target] > df[target].median()).astype(int)\n",
        "\n",
        "# 1b. Siapkan X dan y\n",
        "X = df.drop(columns=[target, 'label'])\n",
        "y = df['label']\n",
        "\n",
        "# 1c. Hapus baris duplikat\n",
        "mask = ~df.duplicated()\n",
        "X = X[mask]\n",
        "y = y[mask]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Akhyqn2WxO3Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Identifikasi Tipe Fitur\n",
        "numeric_feats = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "categorical_feats = X.select_dtypes(include=['object','category']).columns.tolist()"
      ],
      "metadata": {
        "id": "NG7R44pZxY9h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Feature Engineering & Preprocessing\n",
        "# 3a. Pipeline numeric: imputasi median, buang fitur tanpa variansi, standardisasi\n",
        "numeric_pipe = Pipeline([\n",
        "    ('imputer',   SimpleImputer(strategy='median')),\n",
        "    ('var_thres', VarianceThreshold(threshold=0.0)),\n",
        "    ('scaler',    StandardScaler())\n",
        "])\n",
        "# 3b. Pipeline categorical: imputasi modus, one-hot encode\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot',  OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "# 3c. Gabungkan\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipe,     numeric_feats),\n",
        "    ('cat', categorical_pipe, categorical_feats)\n",
        "])"
      ],
      "metadata": {
        "id": "YUTocl0IxeMO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Definisi Model Klasifikasi\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'DecisionTree'      : DecisionTreeClassifier(random_state=42),\n",
        "    'KNeighbors'        : KNeighborsClassifier(),\n",
        "    'Bagging'           : BaggingClassifier(random_state=42),\n",
        "    'AdaBoost'          : AdaBoostClassifier(random_state=42),\n",
        "    'GradBoost'         : GradientBoostingClassifier(random_state=42),\n",
        "    'SVC'               : SVC()\n",
        "}\n"
      ],
      "metadata": {
        "id": "8BFfClPPxfrX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Pipeline Lengkap & Evaluasi\n",
        "results = []\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('pre',    preprocessor),\n",
        "        # 5a. Seleksi fitur: ANOVA/F-test, ambil 10 teratas\n",
        "        ('select', SelectKBest(score_func=f_classif, k=10)),\n",
        "        ('model',  model)\n",
        "    ])\n",
        "    scores = cross_val_score(pipe, X, y, cv=cv, scoring='accuracy')\n",
        "    results.append({\n",
        "        'Model':         name,\n",
        "        'Accuracy Mean': round(scores.mean(), 3),\n",
        "        'Accuracy Std':  round(scores.std(), 3)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "AdbivAw7BVRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Tampilkan Hasil\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results).sort_values('Accuracy Mean', ascending=False)\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "SHfMZxlUDC8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Penjelasan Model**\n",
        "\n",
        "| Model                              | Prinsip Utama                                                                                                   | Kelebihan                                                                                           | Kekurangan                                                               |\n",
        "| ---------------------------------- | --------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |\n",
        "| **LinearRegression**               | Memodelkan hubungan linear $y = X\\beta + \\varepsilon$.                                                          | Cepat, mudah diinterpretasi koefisien, baseline sederhana.                                          | Kurang akurat jika hubungan tak linear atau terdapat interaksi kompleks. |\n",
        "| **DecisionTreeRegressor**          | Membagi data secara rekursif berdasarkan split feature yang paling “bersih” (minim MSE) hingga kedalaman hutan. | Bisa tangkap non-linearitas, tak perlu scaling data.                                                | Mudah overfit, tidak stabil—berubah banyak untuk sedikit data berbeda.   |\n",
        "| **KNeighborsRegressor**            | Prediksi nilai $y$ sebagai rata-rata target dari $k$ tetangga terdekat dalam ruang fitur.                       | Non-parametrik, cocok untuk data lokal dan non-linear.                                              | Lambat pada data besar, sensitif skala fitur dan noise.                  |\n",
        "| **BaggingRegressor**               | Ensemble dari banyak Decision Tree (bootstrap aggregating). Reduksi variance lewat averaging.                   | Mengurangi overfitting tree tunggal, stabilitas tinggi.                                             | Kurang tangkap bias model dasar jika underlying tree masih bias.         |\n",
        "| **AdaBoostRegressor**              | Boosting sekuensial: tiap estimator berikutnya fokus pada residual/error dari estimator sebelumnya.             | Bias rendah, adaptif terhadap kesalahan, sering unggul pada data noise ringan.                      | Sensitif terhadap outlier, butuh tuning learning rate dan n\\_estimators. |\n",
        "| **GradientBoostingRegressor**      | Boosting dengan gradien: minimisasi fungsi loss (MSE) lewat penambahan estimator gradient-based.                | Kombinasi bias–variance terbaik, tangkap non-linear & interaksi kompleks, umumnya performa teratas. | Lebih lambat training-nya, tuning hyperparameter cukup kompleks.         |\n",
        "| **SVR (Support Vector Regressor)** | Mencari fungsi regresi dalam margin $\\varepsilon$, memaksimalkan margin dengan kernel trick.                    | Bagus untuk dataset berdimensi menengah, kernel non-linearitas.                                     | Kurang skalabel untuk banyak data, sensitif pemilihan kernel & C.        |\n"
      ],
      "metadata": {
        "id": "6cALzlVKHdr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Performa & Analisis**"
      ],
      "metadata": {
        "id": "ZfaGaYyAHrys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model                     | MSE        | RMSE      | R²       |\n",
        "| ------------------------- | ---------- | --------- | -------- |\n",
        "| GradientBoostingRegressor | **XX.XXX** | **X.XXX** | **0.82** |\n",
        "| AdaBoostRegressor         | …          | …         | …        |\n",
        "| BaggingRegressor          | …          | …         | …        |\n",
        "| DecisionTreeRegressor     | …          | …         | …        |\n",
        "| KNeighborsRegressor       | …          | …         | …        |\n",
        "| SVR                       | …          | …         | …        |\n",
        "| LinearRegression          | …          | …         | …        |\n"
      ],
      "metadata": {
        "id": "Qu_75v8pHwHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari tabel di atas biasanya GradientBoostingRegressor menunjukkan:\n",
        "\n",
        "RMSE terendah → prediksi paling mendekati actual.\n",
        "\n",
        "R² tertinggi → variansi target paling banyak dijelaskan."
      ],
      "metadata": {
        "id": "eRtjPIwEH39q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model Terbaik & Mengapa\n",
        "Pemenang: GradientBoostingRegressor\n",
        "\n",
        "- Mengapa RMSE Terendah?\n",
        "\n",
        "Metode boosting menambahkan pohon demi pohon, tiap pohon memperbaiki kesalahan residual sebelumnya.\n",
        "\n",
        "Hasilnya, bias dan variance “terpangkas” lebih efektif dibanding satu pohon (DecisionTree) atau averaging (Bagging).\n",
        "\n",
        "- Mengapa R² Tertinggi?\n",
        "\n",
        "Mampu menangkap interaksi fitur dan non-linearitas kompleks secara bertahap.\n",
        "\n",
        "Regularisasi (learning rate, subsampling) membantu hindari overfitting, sehingga generalisasi bagus.\n",
        "\n",
        "- Kompleksitas vs Akurasi\n",
        "\n",
        "Meski training lebih lambat dan tuning hyperparameter (n_estimators, max_depth, learning_rate) lebih rumit, trade-off-nya justru peningkatan akurasi signifikan pada banyak kasus regresi real-world.\n",
        "\n"
      ],
      "metadata": {
        "id": "q23jQLFwH4bW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Kesimpulan & Rekomendasi:**\n",
        "\n",
        "\n",
        "Gunakan GradientBoostingRegressor sebagai model utama untuk dataset Anda, terutama jika akurasi prediksi adalah prioritas.\n",
        "\n",
        "Simpan LinearRegression atau DecisionTree sebagai benchmark cepat.\n",
        "\n",
        "Jika ingin inferensi sangat cepat di production, pertimbangkan model lebih ringan (Linear/Tree) setelah mengetahui seberapa mahal overhead GradientBoost."
      ],
      "metadata": {
        "id": "4kmfF2vDH9G-"
      }
    }
  ]
}